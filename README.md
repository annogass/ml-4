მოდელი 1 — simple_cnn_v1 

პირველი მოდელი წარმოადგენს მარტივ კონვოლუციურ ნეირონულ ქსელს (CNN), სახელად SimpleCNN, რომელიც გამოიყენება FER (Facial Expression Recognition) ამოცანის გადასაჭრელად. არქიტექტურა შედგება ორი Convolutional ფენისგან, MaxPooling ფენებისგან და ორი Fully Connected ფენისგან.

არქიტექტურა:
Conv2D (1→32), kernel=3, padding=1
ReLU
MaxPooling2D (2×2)
Conv2D (32→64), kernel=3, padding=1
ReLU
MaxPooling2D (2×2)
FC1: 64×12×12 → 128
Dropout(0.5)
FC2: 128 → 7 (ემოციის კლასები)

ჰიპერპარამეტრები:
ოპტიმიზატორი: Adam
Learning rate: 0.001
Batch size: 64
Epoch-ები: 15

შედეგები:
საბოლოო Train Accuracy: 58.0%
საბოლოო Validation Accuracy: 53.1%
Train Loss (epoch 15): 1.0813
Val Loss (epoch 15): 1.2441

ანალიზი:
მოდელმა აჩვენა პროგრესული გაუმჯობესება სწავლის პროცესში — ყოველ apoch-ზე ტრენინგისა და ვალიდაციის სიზუსტე თანდათან იზრდებოდა. თუმცა, საბოლოო შედეგებიდან ჩანს, რომ მოდელს დაძლეული აქვს ნაწილობრივი overfitting: ტრენინგის სიზუსტე უფრო მაღალია.




მოდელი 2 – SimpleCNN-v2_Deeper_SGD.ipynb
ამ მოდელში შევიტანე მნიშვნელოვანი არქიტექტურული და ჰიპერპარამეტრების ცვლილებები SimpleCNN-ის პირველ ვერსიასთან შედარებით.

არქიტექტურა:
SimpleCNN-v2_Deeper_SGD.ipynb დაფუძნებულია უფრო ღრმა კონვოლუციურ ნეირონულ ქსელზე. მთავარი ცვლილებაა მესამე Conv ფენის დამატება, რაც ქსელს აძლევს მეტ შესაძლებლობას ამოიცნოს სიღრმისეული და კომპლექსური ფუნქციები.

სტრუქტურა:
Conv2D (1→32), kernel=3, padding=1 → ReLU → MaxPool
Conv2D (32→64), kernel=3, padding=1 → ReLU → MaxPool
Conv2D (64→128), kernel=3, padding=1 → ReLU → MaxPool
Flatten (გამობრტყელება)
Fully Connected (128×6×6 → 256) → ReLU → Dropout(0.5)
Fully Connected (256 → 7) → გამოსავალი (logits)

გამოყენებული პარამეტრები:
ოპტიმიზატორი: SGD (lr=0.01, momentum=0.9)
Batch size: 64
Epoch-ები: 20
Learning rate scheduler: არ გამოყენებულა

ნორმალიზაცია: Pixel values / 255
Dataset: FER2013 (icml_face_data.csv) — გამოყენებულია Training და PrivateTest ნაწილები
Weight decay ან სხვა რეგულარიზაცია: არ გამოყენებულა

ცვლილებები პირველი მოდელიდან:
დამატებულია მესამე Convolution ფენა (Conv3) – რაც საშუალებას აძლევს მოდელს ისწავლოს უფრო ღრმა ვიზუალური მახასიათებლები.
Fully connected ფენა გაფართოვდა – ახლა აქვს 256 ნეირონი FC1-ში (პირველ ვერსიაში იყო 128).
ოპტიმიზატორი შეიცვალა – Adam-დან SGD-ზე გადადით, რაც ხშირად საჭიროებს მეტ Epoch-ს, თუმცა იძლევა უკეთეს გენერალიზაციას.
Epoch-ების რაოდენობა გაზრდილია 15-დან 20-მდე – ადაპტირებული ოპტიმიზატორის შეცვლასთან.

შედეგები და ანალიზი 
მეორე მოდელში შევნიშნე აშკარა გაუმჯობესება პირველთან შედარებით. Train Accuracy გაიზარდა 58%-დან 78%-მდე, ხოლო Validation Accuracy გაიზარდა 53%-დან 58%-მდე. ეს მიუთითებს, რომ მოდელმა უკეთ ისწავლა მონაცემებიდან, განსაკუთრებით მესამე Convolution ფენის და SGD ოპტიმიზატორის დამსახურებით.
მიუხედავად იმისა, რომ Train Accuracy საკმაოდ მაღალია, Validation Accuracy შედარებით ჩამორჩება და ბოლო Epoch-ებში შეინიშნება overfitting-ის ნიშნები – რაც ბუნებრივია უფრო ღრმა მოდელებისთვის.
Val Accuracy მერყეობდა 42%-დან 58%-მდე, ხოლო საუკეთესო შედეგი მივიღე Epoch 20-ზე – Val Accuracy: 58.5%. მთლიანობაში, ეს მოდელი ბევრად უკეთ მუშაობს, ვიდრე პირველი მარტივი CNN.


